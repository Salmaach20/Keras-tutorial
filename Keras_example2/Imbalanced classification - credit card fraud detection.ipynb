{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8fcd5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ea8006e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis example looks at the Kaggle Credit Card Fraud Detection dataset to demonstrate how to train a classification model on data with highly imbalanced classes.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This example looks at the Kaggle Credit Card Fraud Detection dataset to demonstrate how to train a classification model on data with highly imbalanced classes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a68f79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries that we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d2ce06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1ed6752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, vectorize the CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c5e3b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEADER: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
      "EXAMPLE FEATURES: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n",
      "features.shape: (284807, 30)\n",
      "targets.shape: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "# Get the real data from https://www.kaggle.com/mlg-ulb/creditcardfraud/\n",
    "fname = \"C:/Users/salma/Downloads/creditcard.csv/creditcard.csv\"\n",
    "\n",
    "all_features = []\n",
    "all_targets = []\n",
    "with open(fname) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 0:\n",
    "            print(\"HEADER:\", line.strip())\n",
    "            continue  # Skip header\n",
    "        fields = line.strip().split(\",\")\n",
    "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
    "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
    "        if i == 1:\n",
    "            print(\"EXAMPLE FEATURES:\", all_features[-1])\n",
    "\n",
    "features = np.array(all_features, dtype=\"float32\")\n",
    "targets = np.array(all_targets, dtype=\"uint8\")\n",
    "print(\"features.shape:\", features.shape)\n",
    "print(\"targets.shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff2f8407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a80a811c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 227846\n",
      "Number of validation samples: 56961\n"
     ]
    }
   ],
   "source": [
    "num_val_samples = int(len(features) * 0.2)\n",
    "train_features = features[:-num_val_samples]\n",
    "train_targets = targets[:-num_val_samples]\n",
    "val_features = features[-num_val_samples:]\n",
    "val_targets = targets[-num_val_samples:]\n",
    "\n",
    "print(\"Number of training samples:\", len(train_features))\n",
    "print(\"Number of validation samples:\", len(val_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eb51066",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyze class imbalance in the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ab8ad08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples in training data: 417 (0.18% of total)\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(train_targets[:, 0])\n",
    "print(\n",
    "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
    "        counts[1], 100 * float(counts[1]) / len(train_targets)\n",
    "    )\n",
    ")\n",
    "\n",
    "weight_for_0 = 1.0 / counts[0]\n",
    "weight_for_1 = 1.0 / counts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9af3a09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the data using training set statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ac94e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(train_features, axis=0)\n",
    "train_features -= mean\n",
    "val_features -= mean\n",
    "std = np.std(train_features, axis=0)\n",
    "train_features /= std\n",
    "val_features /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fed6e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a binary classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d18c5057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               7936      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,777\n",
      "Trainable params: 139,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            256, activation=\"relu\", input_shape=(train_features.shape[-1],)\n",
    "        ),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13ca17bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model with class_weight argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9a3de1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "112/112 - 8s - loss: 2.2897e-06 - fn: 50.0000 - fp: 19515.0000 - tn: 207914.0000 - tp: 367.0000 - precision: 0.0185 - recall: 0.8801 - val_loss: 0.1064 - val_fn: 10.0000 - val_fp: 752.0000 - val_tn: 56134.0000 - val_tp: 65.0000 - val_precision: 0.0796 - val_recall: 0.8667 - 8s/epoch - 72ms/step\n",
      "Epoch 2/30\n",
      "112/112 - 5s - loss: 1.4127e-06 - fn: 39.0000 - fp: 6193.0000 - tn: 221236.0000 - tp: 378.0000 - precision: 0.0575 - recall: 0.9065 - val_loss: 0.0974 - val_fn: 9.0000 - val_fp: 1102.0000 - val_tn: 55784.0000 - val_tp: 66.0000 - val_precision: 0.0565 - val_recall: 0.8800 - 5s/epoch - 44ms/step\n",
      "Epoch 3/30\n",
      "112/112 - 4s - loss: 1.1668e-06 - fn: 24.0000 - fp: 7316.0000 - tn: 220113.0000 - tp: 393.0000 - precision: 0.0510 - recall: 0.9424 - val_loss: 0.0327 - val_fn: 10.0000 - val_fp: 396.0000 - val_tn: 56490.0000 - val_tp: 65.0000 - val_precision: 0.1410 - val_recall: 0.8667 - 4s/epoch - 39ms/step\n",
      "Epoch 4/30\n",
      "112/112 - 4s - loss: 9.9817e-07 - fn: 27.0000 - fp: 6580.0000 - tn: 220849.0000 - tp: 390.0000 - precision: 0.0560 - recall: 0.9353 - val_loss: 0.0400 - val_fn: 8.0000 - val_fp: 454.0000 - val_tn: 56432.0000 - val_tp: 67.0000 - val_precision: 0.1286 - val_recall: 0.8933 - 4s/epoch - 35ms/step\n",
      "Epoch 5/30\n",
      "112/112 - 4s - loss: 9.3344e-07 - fn: 25.0000 - fp: 7310.0000 - tn: 220119.0000 - tp: 392.0000 - precision: 0.0509 - recall: 0.9400 - val_loss: 0.1098 - val_fn: 5.0000 - val_fp: 2327.0000 - val_tn: 54559.0000 - val_tp: 70.0000 - val_precision: 0.0292 - val_recall: 0.9333 - 4s/epoch - 36ms/step\n",
      "Epoch 6/30\n",
      "112/112 - 5s - loss: 1.1349e-06 - fn: 21.0000 - fp: 7984.0000 - tn: 219445.0000 - tp: 396.0000 - precision: 0.0473 - recall: 0.9496 - val_loss: 0.0345 - val_fn: 10.0000 - val_fp: 629.0000 - val_tn: 56257.0000 - val_tp: 65.0000 - val_precision: 0.0937 - val_recall: 0.8667 - 5s/epoch - 41ms/step\n",
      "Epoch 7/30\n",
      "112/112 - 4s - loss: 6.9843e-07 - fn: 19.0000 - fp: 6570.0000 - tn: 220859.0000 - tp: 398.0000 - precision: 0.0571 - recall: 0.9544 - val_loss: 0.0374 - val_fn: 8.0000 - val_fp: 581.0000 - val_tn: 56305.0000 - val_tp: 67.0000 - val_precision: 0.1034 - val_recall: 0.8933 - 4s/epoch - 35ms/step\n",
      "Epoch 8/30\n",
      "112/112 - 4s - loss: 7.2399e-07 - fn: 11.0000 - fp: 6733.0000 - tn: 220696.0000 - tp: 406.0000 - precision: 0.0569 - recall: 0.9736 - val_loss: 0.1005 - val_fn: 5.0000 - val_fp: 2502.0000 - val_tn: 54384.0000 - val_tp: 70.0000 - val_precision: 0.0272 - val_recall: 0.9333 - 4s/epoch - 34ms/step\n",
      "Epoch 9/30\n",
      "112/112 - 4s - loss: 6.7854e-07 - fn: 12.0000 - fp: 7927.0000 - tn: 219502.0000 - tp: 405.0000 - precision: 0.0486 - recall: 0.9712 - val_loss: 0.0356 - val_fn: 7.0000 - val_fp: 899.0000 - val_tn: 55987.0000 - val_tp: 68.0000 - val_precision: 0.0703 - val_recall: 0.9067 - 4s/epoch - 35ms/step\n",
      "Epoch 10/30\n",
      "112/112 - 5s - loss: 7.0942e-07 - fn: 10.0000 - fp: 6796.0000 - tn: 220633.0000 - tp: 407.0000 - precision: 0.0565 - recall: 0.9760 - val_loss: 0.0721 - val_fn: 7.0000 - val_fp: 1565.0000 - val_tn: 55321.0000 - val_tp: 68.0000 - val_precision: 0.0416 - val_recall: 0.9067 - 5s/epoch - 40ms/step\n",
      "Epoch 11/30\n",
      "112/112 - 4s - loss: 4.6163e-07 - fn: 9.0000 - fp: 5313.0000 - tn: 222116.0000 - tp: 408.0000 - precision: 0.0713 - recall: 0.9784 - val_loss: 0.0249 - val_fn: 7.0000 - val_fp: 499.0000 - val_tn: 56387.0000 - val_tp: 68.0000 - val_precision: 0.1199 - val_recall: 0.9067 - 4s/epoch - 35ms/step\n",
      "Epoch 12/30\n",
      "112/112 - 4s - loss: 4.7601e-07 - fn: 7.0000 - fp: 5679.0000 - tn: 221750.0000 - tp: 410.0000 - precision: 0.0673 - recall: 0.9832 - val_loss: 0.0200 - val_fn: 11.0000 - val_fp: 470.0000 - val_tn: 56416.0000 - val_tp: 64.0000 - val_precision: 0.1199 - val_recall: 0.8533 - 4s/epoch - 34ms/step\n",
      "Epoch 13/30\n",
      "112/112 - 4s - loss: 5.0822e-07 - fn: 5.0000 - fp: 4832.0000 - tn: 222597.0000 - tp: 412.0000 - precision: 0.0786 - recall: 0.9880 - val_loss: 0.0455 - val_fn: 10.0000 - val_fp: 1024.0000 - val_tn: 55862.0000 - val_tp: 65.0000 - val_precision: 0.0597 - val_recall: 0.8667 - 4s/epoch - 35ms/step\n",
      "Epoch 14/30\n",
      "112/112 - 5s - loss: 4.8233e-07 - fn: 9.0000 - fp: 5085.0000 - tn: 222344.0000 - tp: 408.0000 - precision: 0.0743 - recall: 0.9784 - val_loss: 0.0441 - val_fn: 9.0000 - val_fp: 990.0000 - val_tn: 55896.0000 - val_tp: 66.0000 - val_precision: 0.0625 - val_recall: 0.8800 - 5s/epoch - 41ms/step\n",
      "Epoch 15/30\n",
      "112/112 - 4s - loss: 5.0860e-07 - fn: 6.0000 - fp: 6559.0000 - tn: 220870.0000 - tp: 411.0000 - precision: 0.0590 - recall: 0.9856 - val_loss: 0.0529 - val_fn: 7.0000 - val_fp: 1322.0000 - val_tn: 55564.0000 - val_tp: 68.0000 - val_precision: 0.0489 - val_recall: 0.9067 - 4s/epoch - 38ms/step\n",
      "Epoch 16/30\n",
      "112/112 - 5s - loss: 4.9334e-07 - fn: 7.0000 - fp: 5876.0000 - tn: 221553.0000 - tp: 410.0000 - precision: 0.0652 - recall: 0.9832 - val_loss: 0.0572 - val_fn: 7.0000 - val_fp: 1154.0000 - val_tn: 55732.0000 - val_tp: 68.0000 - val_precision: 0.0556 - val_recall: 0.9067 - 5s/epoch - 41ms/step\n",
      "Epoch 17/30\n",
      "112/112 - 5s - loss: 4.4394e-07 - fn: 7.0000 - fp: 5780.0000 - tn: 221649.0000 - tp: 410.0000 - precision: 0.0662 - recall: 0.9832 - val_loss: 0.0308 - val_fn: 8.0000 - val_fp: 822.0000 - val_tn: 56064.0000 - val_tp: 67.0000 - val_precision: 0.0754 - val_recall: 0.8933 - 5s/epoch - 48ms/step\n",
      "Epoch 18/30\n",
      "112/112 - 5s - loss: 4.0739e-07 - fn: 4.0000 - fp: 5053.0000 - tn: 222376.0000 - tp: 413.0000 - precision: 0.0756 - recall: 0.9904 - val_loss: 0.0139 - val_fn: 10.0000 - val_fp: 312.0000 - val_tn: 56574.0000 - val_tp: 65.0000 - val_precision: 0.1724 - val_recall: 0.8667 - 5s/epoch - 45ms/step\n",
      "Epoch 19/30\n",
      "112/112 - 5s - loss: 2.8926e-07 - fn: 4.0000 - fp: 3524.0000 - tn: 223905.0000 - tp: 413.0000 - precision: 0.1049 - recall: 0.9904 - val_loss: 0.0267 - val_fn: 9.0000 - val_fp: 493.0000 - val_tn: 56393.0000 - val_tp: 66.0000 - val_precision: 0.1181 - val_recall: 0.8800 - 5s/epoch - 41ms/step\n",
      "Epoch 20/30\n",
      "112/112 - 5s - loss: 3.8047e-07 - fn: 6.0000 - fp: 4400.0000 - tn: 223029.0000 - tp: 411.0000 - precision: 0.0854 - recall: 0.9856 - val_loss: 0.0477 - val_fn: 7.0000 - val_fp: 1135.0000 - val_tn: 55751.0000 - val_tp: 68.0000 - val_precision: 0.0565 - val_recall: 0.9067 - 5s/epoch - 46ms/step\n",
      "Epoch 21/30\n",
      "112/112 - 5s - loss: 4.1295e-07 - fn: 5.0000 - fp: 5240.0000 - tn: 222189.0000 - tp: 412.0000 - precision: 0.0729 - recall: 0.9880 - val_loss: 0.0272 - val_fn: 9.0000 - val_fp: 824.0000 - val_tn: 56062.0000 - val_tp: 66.0000 - val_precision: 0.0742 - val_recall: 0.8800 - 5s/epoch - 47ms/step\n",
      "Epoch 22/30\n",
      "112/112 - 5s - loss: 3.3695e-07 - fn: 3.0000 - fp: 4955.0000 - tn: 222474.0000 - tp: 414.0000 - precision: 0.0771 - recall: 0.9928 - val_loss: 0.0371 - val_fn: 8.0000 - val_fp: 799.0000 - val_tn: 56087.0000 - val_tp: 67.0000 - val_precision: 0.0774 - val_recall: 0.8933 - 5s/epoch - 42ms/step\n",
      "Epoch 23/30\n",
      "112/112 - 5s - loss: 2.6339e-07 - fn: 4.0000 - fp: 3075.0000 - tn: 224354.0000 - tp: 413.0000 - precision: 0.1184 - recall: 0.9904 - val_loss: 0.0108 - val_fn: 11.0000 - val_fp: 158.0000 - val_tn: 56728.0000 - val_tp: 64.0000 - val_precision: 0.2883 - val_recall: 0.8533 - 5s/epoch - 44ms/step\n",
      "Epoch 24/30\n",
      "112/112 - 5s - loss: 3.2061e-07 - fn: 5.0000 - fp: 4251.0000 - tn: 223178.0000 - tp: 412.0000 - precision: 0.0884 - recall: 0.9880 - val_loss: 0.0387 - val_fn: 7.0000 - val_fp: 1127.0000 - val_tn: 55759.0000 - val_tp: 68.0000 - val_precision: 0.0569 - val_recall: 0.9067 - 5s/epoch - 49ms/step\n",
      "Epoch 25/30\n",
      "112/112 - 5s - loss: 3.4644e-07 - fn: 4.0000 - fp: 4685.0000 - tn: 222744.0000 - tp: 413.0000 - precision: 0.0810 - recall: 0.9904 - val_loss: 0.0203 - val_fn: 9.0000 - val_fp: 531.0000 - val_tn: 56355.0000 - val_tp: 66.0000 - val_precision: 0.1106 - val_recall: 0.8800 - 5s/epoch - 41ms/step\n",
      "Epoch 26/30\n",
      "112/112 - 5s - loss: 2.1436e-07 - fn: 2.0000 - fp: 2312.0000 - tn: 225117.0000 - tp: 415.0000 - precision: 0.1522 - recall: 0.9952 - val_loss: 0.1330 - val_fn: 5.0000 - val_fp: 2879.0000 - val_tn: 54007.0000 - val_tp: 70.0000 - val_precision: 0.0237 - val_recall: 0.9333 - 5s/epoch - 42ms/step\n",
      "Epoch 27/30\n",
      "112/112 - 6s - loss: 5.0939e-07 - fn: 5.0000 - fp: 7397.0000 - tn: 220032.0000 - tp: 412.0000 - precision: 0.0528 - recall: 0.9880 - val_loss: 0.0846 - val_fn: 8.0000 - val_fp: 2147.0000 - val_tn: 54739.0000 - val_tp: 67.0000 - val_precision: 0.0303 - val_recall: 0.8933 - 6s/epoch - 50ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "112/112 - 5s - loss: 4.3552e-07 - fn: 3.0000 - fp: 4067.0000 - tn: 223362.0000 - tp: 414.0000 - precision: 0.0924 - recall: 0.9928 - val_loss: 0.1918 - val_fn: 5.0000 - val_fp: 3408.0000 - val_tn: 53478.0000 - val_tp: 70.0000 - val_precision: 0.0201 - val_recall: 0.9333 - 5s/epoch - 42ms/step\n",
      "Epoch 29/30\n",
      "112/112 - 5s - loss: 7.9831e-07 - fn: 8.0000 - fp: 7585.0000 - tn: 219844.0000 - tp: 409.0000 - precision: 0.0512 - recall: 0.9808 - val_loss: 0.0460 - val_fn: 10.0000 - val_fp: 449.0000 - val_tn: 56437.0000 - val_tp: 65.0000 - val_precision: 0.1265 - val_recall: 0.8667 - 5s/epoch - 41ms/step\n",
      "Epoch 30/30\n",
      "112/112 - 6s - loss: 5.0937e-07 - fn: 4.0000 - fp: 5019.0000 - tn: 222410.0000 - tp: 413.0000 - precision: 0.0760 - recall: 0.9904 - val_loss: 0.0294 - val_fn: 10.0000 - val_fp: 638.0000 - val_tn: 56248.0000 - val_tp: 65.0000 - val_precision: 0.0925 - val_recall: 0.8667 - 6s/epoch - 50ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2214ae190f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
    ")\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.h5\")]\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "model.fit(\n",
    "    train_features,\n",
    "    train_targets,\n",
    "    batch_size=2048,\n",
    "    epochs=30,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(val_features, val_targets),\n",
    "    class_weight=class_weight,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "201d4eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d416287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAt the end of training, out of 56,961 validation transactions, we are:\\n\\n1- Correctly identifying 66 of them as fraudulent\\n2- Missing 9 fraudulent transactions\\n3- At the cost of incorrectly flagging 441 legitimate transactions\\n\\nIn the real world, one would put an even higher weight on class 1, so as to reflect that False Negatives are more costly than False Positives.\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "At the end of training, out of 56,961 validation transactions, we are:\n",
    "\n",
    "1- Correctly identifying 66 of them as fraudulent\n",
    "2- Missing 9 fraudulent transactions\n",
    "3- At the cost of incorrectly flagging 441 legitimate transactions\n",
    "\n",
    "In the real world, one would put an even higher weight on class 1, so as to reflect that False Negatives are more costly than False Positives.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a866aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
